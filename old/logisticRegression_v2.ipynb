{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import random\n",
    "import datetime\n",
    "import sklearn.linear_model as skl_lm\n",
    "import matplotlib.pyplot as plt \n",
    "import utilities as utils\n",
    "import fractionalDiff as fd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = pd.read_excel('../Data/candles.xlsx')\n",
    "logicOutputs = pd.read_excel('../Data/bitcoin.xlsx')\n",
    "tickers = ['indicator']\n",
    "inputVariables = inputs.columns[2:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['low', 'high', 'open', 'close', 'volume', 'ma', 'UpperBB', 'LowerBB'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.columns[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transformedInputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\daniele.sicoli\\Documents\\prj\\data_driven_stochastic\\Data_driven_stochastic\\logistic_regression\\logisticRegression_v2.ipynb Cell 4'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/daniele.sicoli/Documents/prj/data_driven_stochastic/Data_driven_stochastic/logistic_regression/logisticRegression_v2.ipynb#ch0000003?line=0'>1</a>\u001b[0m transformedInputs\n",
      "\u001b[1;31mNameError\u001b[0m: name 'transformedInputs' is not defined"
     ]
    }
   ],
   "source": [
    "transformedInputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differencing order: 0.8\n",
      "Temporal window: 7\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "pTrain = 0.7\n",
    "window_0 = 7\n",
    "nDaysInWindow = 1/24\n",
    "deltaWindow = 0\n",
    "\n",
    "\n",
    "cutoff = 1e-1\n",
    "\n",
    "orders = np.linspace(.8, .8, 1)\n",
    "\n",
    "scoresByOrderLst = []\n",
    "\n",
    "for order in orders:\n",
    "    print(f'Differencing order: {order}')\n",
    "\n",
    "    lags = fd.findCutoff(order,cutoff,1)\n",
    "    transformedInputs = fd.TransformInputs(inputs, inputVariables, order = order, thresholdVal = cutoff)[lags:]\n",
    "\n",
    "    scoresLst = []\n",
    "\n",
    "    \n",
    "    ######################################### window loop starts #########################################\n",
    "    for window in range(window_0, window_0 + deltaWindow + 1):\n",
    "        print(f'Temporal window: {window}')\n",
    "        trainScores = []\n",
    "        testScores = []\n",
    "        scoresWithTickersLst = []\n",
    "        backtestDates = []\n",
    "        stopDates = inputs.date[window:(inputs.date.shape[0])]\n",
    "        #stopDates = [inputs.date[(inputs.date.shape[0])]]\n",
    "\n",
    "        for ticker in tickers:\n",
    "            \n",
    "            for stopDate in stopDates:\n",
    "                \n",
    "                startDate = stopDate + datetime.timedelta(days=-(nDaysInWindow*window))\n",
    "\n",
    "                x, y = utils.PrepareInputs(transformedInputs, logicOutputs[lags:], startDate, stopDate, ticker)\n",
    "                \n",
    "                nTrain = int(pTrain * x.shape[0])\n",
    "                x = np.nan_to_num(x)\n",
    "                \n",
    "                xTrain, xTest, yTrain, yTest = utils.TestTrainSplit(x, y, nTrain)\n",
    "    \n",
    "                if len(np.unique(yTrain)) < 2:\n",
    "                    continue\n",
    "                \n",
    "                lrm = skl_lm.LogisticRegression(random_state=0, verbose = 0).fit(xTrain, yTrain)\n",
    "                trainScores.append(lrm.score(xTrain, yTrain))\n",
    "                testScores.append(lrm.score(xTest, yTest))            \n",
    "                backtestDates.append(stopDate)\n",
    "                \n",
    "\n",
    "            scoresWithTickers = pd.DataFrame(list(zip(backtestDates, trainScores, testScores)), columns = ['stopDate', 'train', 'test'])\n",
    "            scoresWithTickers['ticker'] = ticker \n",
    "            scoresWithTickersLst.append(scoresWithTickers)\n",
    "\n",
    "    #################################################### window loop ends #######################################################################\n",
    "\n",
    "        scores = pd.concat(scoresWithTickersLst)\n",
    "        scores['window'] = window\n",
    "        scoresLst.append(scores)\n",
    "\n",
    "    scoresDf = pd.concat(scoresLst)\n",
    "    scoresDf['order'] = order\n",
    "    scoresByOrderLst.append(scoresDf)\n",
    "\n",
    "scoresByOrder = pd.concat(scoresByOrderLst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  1, -1], dtype=int64),\n",
       " array([-1,  1,  1,  1], dtype=int64),\n",
       " array([1, 1, 1], dtype=int64),\n",
       " array([1], dtype=int64))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTest, lrm.predict(xTrain), lrm.predict(xTest), lrm.predict(xTest[1].reshape((1, 8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05365535],\n",
       "       [ 0.19190272],\n",
       "       [ 0.3969945 ],\n",
       "       [ 0.42158509],\n",
       "       [-0.04406998],\n",
       "       [ 0.98091542],\n",
       "       [ 0.73449539],\n",
       "       [-0.18636924]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTest[1].reshape((8, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order</th>\n",
       "      <th>window</th>\n",
       "      <th>trainMedian</th>\n",
       "      <th>trainStd</th>\n",
       "      <th>testMedian</th>\n",
       "      <th>testStd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.134615</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.301922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order  window  trainMedian  trainStd  testMedian   testStd\n",
       "0    0.8       7         0.75  0.134615    0.666667  0.301922"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggScores = scoresByOrder.groupby(['order', 'window']).agg({'train':[np.median, np.std], 'test':[np.median, np.std]}).droplevel(level=[0], axis = 1).reset_index()\n",
    "aggScores.columns = ['order', 'window', 'trainMedian', 'trainStd', 'testMedian', 'testStd']\n",
    "\n",
    "aggScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(lrm, open('../ml_models/btc_mdl_train_2022-04-15_2022-04-30_v2.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ma'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\daniele.sicoli\\Documents\\prj\\data_driven_stochastic\\Data_driven_stochastic\\data_driven-venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/daniele.sicoli/Documents/prj/data_driven_stochastic/Data_driven_stochastic/data_driven-venv/lib/site-packages/pandas/core/indexes/base.py?line=3619'>3620</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/daniele.sicoli/Documents/prj/data_driven_stochastic/Data_driven_stochastic/data_driven-venv/lib/site-packages/pandas/core/indexes/base.py?line=3620'>3621</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   <a href='file:///c%3A/Users/daniele.sicoli/Documents/prj/data_driven_stochastic/Data_driven_stochastic/data_driven-venv/lib/site-packages/pandas/core/indexes/base.py?line=3621'>3622</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\daniele.sicoli\\Documents\\prj\\data_driven_stochastic\\Data_driven_stochastic\\data_driven-venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\daniele.sicoli\\Documents\\prj\\data_driven_stochastic\\Data_driven_stochastic\\data_driven-venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ma'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\daniele.sicoli\\Documents\\prj\\data_driven_stochastic\\Data_driven_stochastic\\logistic_regression\\logisticRegression_v2.ipynb Cell 10'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/daniele.sicoli/Documents/prj/data_driven_stochastic/Data_driven_stochastic/logistic_regression/logisticRegression_v2.ipynb#ch0000011?line=0'>1</a>\u001b[0m candles4Backtest \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_excel(\u001b[39m'\u001b[39m\u001b[39m../Data/candles4backtest.xlsx\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/daniele.sicoli/Documents/prj/data_driven_stochastic/Data_driven_stochastic/logistic_regression/logisticRegression_v2.ipynb#ch0000011?line=2'>3</a>\u001b[0m lags \u001b[39m=\u001b[39m fd\u001b[39m.\u001b[39mfindCutoff(order,cutoff,\u001b[39m1\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/daniele.sicoli/Documents/prj/data_driven_stochastic/Data_driven_stochastic/logistic_regression/logisticRegression_v2.ipynb#ch0000011?line=3'>4</a>\u001b[0m transformedInputs \u001b[39m=\u001b[39m fd\u001b[39m.\u001b[39;49mTransformInputs(candles4Backtest, inputVariables, order \u001b[39m=\u001b[39;49m order, thresholdVal \u001b[39m=\u001b[39;49m cutoff)[lags:]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/daniele.sicoli/Documents/prj/data_driven_stochastic/Data_driven_stochastic/logistic_regression/logisticRegression_v2.ipynb#ch0000011?line=4'>5</a>\u001b[0m transformedInputs\n",
      "File \u001b[1;32mc:\\Users\\daniele.sicoli\\Documents\\prj\\data_driven_stochastic\\Data_driven_stochastic\\logistic_regression\\fractionalDiff.py:39\u001b[0m, in \u001b[0;36mTransformInputs\u001b[1;34m(inputs, tickers, order, thresholdVal)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/daniele.sicoli/Documents/prj/data_driven_stochastic/Data_driven_stochastic/logistic_regression/fractionalDiff.py?line=35'>36</a>\u001b[0m transformedInputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m     <a href='file:///c%3A/Users/daniele.sicoli/Documents/prj/data_driven_stochastic/Data_driven_stochastic/logistic_regression/fractionalDiff.py?line=37'>38</a>\u001b[0m \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m tickers:\n\u001b[1;32m---> <a href='file:///c%3A/Users/daniele.sicoli/Documents/prj/data_driven_stochastic/Data_driven_stochastic/logistic_regression/fractionalDiff.py?line=38'>39</a>\u001b[0m     transformedInputs[col] \u001b[39m=\u001b[39m CalculateDifferencedVariables(inputs[col], order, thresholdVal, cutoff\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='file:///c%3A/Users/daniele.sicoli/Documents/prj/data_driven_stochastic/Data_driven_stochastic/logistic_regression/fractionalDiff.py?line=40'>41</a>\u001b[0m \u001b[39mreturn\u001b[39;00m transformedInputs\n",
      "File \u001b[1;32mc:\\Users\\daniele.sicoli\\Documents\\prj\\data_driven_stochastic\\Data_driven_stochastic\\data_driven-venv\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/daniele.sicoli/Documents/prj/data_driven_stochastic/Data_driven_stochastic/data_driven-venv/lib/site-packages/pandas/core/frame.py?line=3502'>3503</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   <a href='file:///c%3A/Users/daniele.sicoli/Documents/prj/data_driven_stochastic/Data_driven_stochastic/data_driven-venv/lib/site-packages/pandas/core/frame.py?line=3503'>3504</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> <a href='file:///c%3A/Users/daniele.sicoli/Documents/prj/data_driven_stochastic/Data_driven_stochastic/data_driven-venv/lib/site-packages/pandas/core/frame.py?line=3504'>3505</a>\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   <a href='file:///c%3A/Users/daniele.sicoli/Documents/prj/data_driven_stochastic/Data_driven_stochastic/data_driven-venv/lib/site-packages/pandas/core/frame.py?line=3505'>3506</a>\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   <a href='file:///c%3A/Users/daniele.sicoli/Documents/prj/data_driven_stochastic/Data_driven_stochastic/data_driven-venv/lib/site-packages/pandas/core/frame.py?line=3506'>3507</a>\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\daniele.sicoli\\Documents\\prj\\data_driven_stochastic\\Data_driven_stochastic\\data_driven-venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/daniele.sicoli/Documents/prj/data_driven_stochastic/Data_driven_stochastic/data_driven-venv/lib/site-packages/pandas/core/indexes/base.py?line=3620'>3621</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   <a href='file:///c%3A/Users/daniele.sicoli/Documents/prj/data_driven_stochastic/Data_driven_stochastic/data_driven-venv/lib/site-packages/pandas/core/indexes/base.py?line=3621'>3622</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> <a href='file:///c%3A/Users/daniele.sicoli/Documents/prj/data_driven_stochastic/Data_driven_stochastic/data_driven-venv/lib/site-packages/pandas/core/indexes/base.py?line=3622'>3623</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/daniele.sicoli/Documents/prj/data_driven_stochastic/Data_driven_stochastic/data_driven-venv/lib/site-packages/pandas/core/indexes/base.py?line=3623'>3624</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/daniele.sicoli/Documents/prj/data_driven_stochastic/Data_driven_stochastic/data_driven-venv/lib/site-packages/pandas/core/indexes/base.py?line=3624'>3625</a>\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/daniele.sicoli/Documents/prj/data_driven_stochastic/Data_driven_stochastic/data_driven-venv/lib/site-packages/pandas/core/indexes/base.py?line=3625'>3626</a>\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/daniele.sicoli/Documents/prj/data_driven_stochastic/Data_driven_stochastic/data_driven-venv/lib/site-packages/pandas/core/indexes/base.py?line=3626'>3627</a>\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/daniele.sicoli/Documents/prj/data_driven_stochastic/Data_driven_stochastic/data_driven-venv/lib/site-packages/pandas/core/indexes/base.py?line=3627'>3628</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ma'"
     ]
    }
   ],
   "source": [
    "candles4Backtest = pd.read_excel('../Data/candles4backtest.xlsx')\n",
    "\n",
    "lags = fd.findCutoff(order,cutoff,1)\n",
    "transformedInputs = fd.TransformInputs(candles4Backtest, inputVariables, order = order, thresholdVal = cutoff)[lags:]\n",
    "transformedInputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "pTrain = 0.7\n",
    "window_0 = 7\n",
    "nDaysInWindow = 1/24\n",
    "deltaWindow = 0\n",
    "\n",
    "\n",
    "cutoff = 1e-1\n",
    "\n",
    "orders = np.linspace(.8, .8, 1)\n",
    "\n",
    "scoresByOrderLst = []\n",
    "\n",
    "for order in orders:\n",
    "    print(f'Differencing order: {order}')\n",
    "\n",
    "    lags = fd.findCutoff(order,cutoff,1)\n",
    "    transformedInputs = fd.TransformInputs(inputs, candles4Backtest, order = order, thresholdVal = cutoff)[lags:]\n",
    "\n",
    "    scoresLst = []\n",
    "\n",
    "    \n",
    "    ######################################### window loop starts #########################################\n",
    "    for window in range(window_0, window_0 + deltaWindow + 1):\n",
    "        print(f'Temporal window: {window}')\n",
    "        trainScores = []\n",
    "        testScores = []\n",
    "        scoresWithTickersLst = []\n",
    "        backtestDates = []\n",
    "        stopDates = inputs.date[window:(inputs.date.shape[0])]\n",
    "        #stopDates = [inputs.date[(inputs.date.shape[0])]]\n",
    "\n",
    "        for ticker in tickers:\n",
    "            \n",
    "            for stopDate in stopDates:\n",
    "                \n",
    "                startDate = stopDate + datetime.timedelta(days=-(nDaysInWindow*window))\n",
    "\n",
    "                x, y = utils.PrepareInputs(transformedInputs, logicOutputs[lags:], startDate, stopDate, ticker)\n",
    "                \n",
    "                nTrain = int(pTrain * x.shape[0])\n",
    "                x = np.nan_to_num(x)\n",
    "                \n",
    "                xTrain, xTest, yTrain, yTest = utils.TestTrainSplit(x, y, nTrain)\n",
    "    \n",
    "                if len(np.unique(yTrain)) < 2:\n",
    "                    continue\n",
    "                \n",
    "                lrm = skl_lm.LogisticRegression(random_state=0, verbose = 0).fit(xTrain, yTrain)\n",
    "                trainScores.append(lrm.score(xTrain, yTrain))\n",
    "                testScores.append(lrm.score(xTest, yTest))            \n",
    "                backtestDates.append(stopDate)\n",
    "                \n",
    "\n",
    "            scoresWithTickers = pd.DataFrame(list(zip(backtestDates, trainScores, testScores)), columns = ['stopDate', 'train', 'test'])\n",
    "            scoresWithTickers['ticker'] = ticker \n",
    "            scoresWithTickersLst.append(scoresWithTickers)\n",
    "\n",
    "    #################################################### window loop ends #######################################################################\n",
    "\n",
    "        scores = pd.concat(scoresWithTickersLst)\n",
    "        scores['window'] = window\n",
    "        scoresLst.append(scores)\n",
    "\n",
    "    scoresDf = pd.concat(scoresLst)\n",
    "    scoresDf['order'] = order\n",
    "    scoresByOrderLst.append(scoresDf)\n",
    "\n",
    "scoresByOrder = pd.concat(scoresByOrderLst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.13335182, -2.1944122 , -2.09168574,  0.49112899, -0.91283131,\n",
       "        -0.99673867, -0.76390267,  0.21238611],\n",
       "       [-1.180612  , -0.45338347,  0.62096807, -0.88134118,  0.41992438,\n",
       "        -1.03279675, -0.59487124, -0.03765504],\n",
       "       [-1.80418693, -0.30161551, -0.22833519, -2.00751759,  1.85591985,\n",
       "        -1.07788184,  0.72731468, -1.80600742],\n",
       "       [ 0.70680864,  0.02082764, -0.89728116,  1.61640193, -1.3646306 ,\n",
       "         1.05684115,  1.08934326, -0.59130777],\n",
       "       [ 1.3116778 ,  0.80299442,  1.34158434,  0.11633267, -0.95518876,\n",
       "         1.435745  ,  1.17264112, -0.40065444],\n",
       "       [-0.05365535,  0.19190272,  0.3969945 ,  0.42158509, -0.04406998,\n",
       "         0.98091542,  0.73449539, -0.18636924],\n",
       "       [ 1.04849295,  0.55672456,  0.59721334, -0.12145794,  0.13400756,\n",
       "        -0.71714552, -1.74628939,  1.7210009 ]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e883445c5a183403f909fb1a8ec320fd574e63b05568c53720d31bd9eb9e509e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('data_driven-venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
